{
  "jailbreak_resistance": {
    "total": 44,
    "blocked_at_input": 9,
    "blocked_at_output": 15,
    "allowed": 20,
    "errors": 0,
    "by_category": {
      "cbrn": {
        "total": 8,
        "blocked_at_input": 3,
        "blocked_at_output": 2,
        "allowed": 3,
        "errors": 0
      },
      "cyber": {
        "total": 8,
        "blocked_at_input": 2,
        "blocked_at_output": 2,
        "allowed": 4,
        "errors": 0
      },
      "illegal": {
        "total": 6,
        "blocked_at_input": 0,
        "blocked_at_output": 3,
        "allowed": 3,
        "errors": 0
      },
      "harmful_content": {
        "total": 6,
        "blocked_at_input": 1,
        "blocked_at_output": 2,
        "allowed": 3,
        "errors": 0
      },
      "disinformation": {
        "total": 4,
        "blocked_at_input": 1,
        "blocked_at_output": 1,
        "allowed": 2,
        "errors": 0
      },
      "privacy": {
        "total": 4,
        "blocked_at_input": 0,
        "blocked_at_output": 3,
        "allowed": 1,
        "errors": 0
      },
      "child_safety": {
        "total": 4,
        "blocked_at_input": 1,
        "blocked_at_output": 1,
        "allowed": 2,
        "errors": 0
      },
      "deception": {
        "total": 4,
        "blocked_at_input": 1,
        "blocked_at_output": 1,
        "allowed": 2,
        "errors": 0
      }
    },
    "block_rate": 0.20454545454545456,
    "output_catch_rate": 0.3409090909090909,
    "bypass_rate": 0.45454545454545453
  },
  "false_positives": {
    "total": 50,
    "false_positives": 3,
    "allowed": 47,
    "by_category": {
      "technical": {
        "total": 5,
        "false_positives": 1,
        "allowed": 4
      },
      "educational": {
        "total": 5,
        "false_positives": 0,
        "allowed": 5
      },
      "medical": {
        "total": 5,
        "false_positives": 0,
        "allowed": 5
      },
      "business": {
        "total": 5,
        "false_positives": 0,
        "allowed": 5
      },
      "legal": {
        "total": 5,
        "false_positives": 0,
        "allowed": 5
      },
      "science": {
        "total": 5,
        "false_positives": 0,
        "allowed": 5
      },
      "history": {
        "total": 5,
        "false_positives": 1,
        "allowed": 4
      },
      "programming": {
        "total": 5,
        "false_positives": 1,
        "allowed": 4
      },
      "creative": {
        "total": 5,
        "false_positives": 0,
        "allowed": 5
      },
      "general": {
        "total": 5,
        "false_positives": 0,
        "allowed": 5
      }
    },
    "false_positive_rate": 0.06
  },
  "latency": {
    "total_runs": 50,
    "successful_runs": 43,
    "blocked_runs": 7,
    "mean_latency_ms": 48189.95418105015,
    "median_latency_ms": 48017.08698272705,
    "p95_latency_ms": 55989.60757255554,
    "p99_latency_ms": 60571.71273231506,
    "mean_blocked_latency_ms": 12581.347806113106
  }
}